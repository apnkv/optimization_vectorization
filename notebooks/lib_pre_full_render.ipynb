{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "from collections import namedtuple\n",
    "from multiprocessing import Pool, Queue\n",
    "from time import sleep\n",
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from geomloss import SamplesLoss\n",
    "from torch import optim\n",
    "from vectran.renderers.cairo import render as cairo_render\n",
    "from vectran.util.evaluation_utils import vector_image_from_patches\n",
    "\n",
    "from vecopt.aligner import (\n",
    "    StatefulBatchAligner,\n",
    "    init_ot_aligner,\n",
    "    make_default_loss_fn,\n",
    "    make_default_optimize_fn,\n",
    ")\n",
    "from vecopt.aligner_utils import (\n",
    "    LossComposition, store_render_difference, \n",
    "    perceptual_bce, strip_confidence_grads, \n",
    "    compose, coords_only_grads\n",
    ")\n",
    "from vecopt.crossing_model import CrossingRefinerFull\n",
    "from vecopt.inference import IntermediateOutputAligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "IntermediateSample = namedtuple('IntermediateSample', ['worker_idx', 'sample', 'filename'])\n",
    "n_workers = 4\n",
    "\n",
    "data = []\n",
    "\n",
    "data_folder = '/home/apankov/vecopt_datasets/results/abc/our_curves/intermediate_output'\n",
    "worker_idx = -1\n",
    "for filename in glob.glob(os.path.join(data_folder, '*')):\n",
    "    path = os.path.join(data_folder, filename)\n",
    "    with open(path, 'rb') as handle:\n",
    "        sample = pickle.load(handle)\n",
    "        \n",
    "    worker_idx = (worker_idx + 1) % n_workers\n",
    "    \n",
    "    data.append(IntermediateSample(worker_idx, sample, filename))\n",
    "    \n",
    "def make_aligner(device, n_steps):\n",
    "    crossing_model = CrossingRefinerFull().to(device)\n",
    "    crossing_model.load_state_dict(torch.load('../vecopt/weights/best_crossings_mult.pt'))\n",
    "    _ = crossing_model.train(False)\n",
    "\n",
    "    loss = LossComposition()\n",
    "    ot_loss = SamplesLoss(\"sinkhorn\", p=2, blur=.01, scaling=.5, reach=5.)\n",
    "    loss.add(make_default_loss_fn(\n",
    "        bce_schedule=(lambda state: 0.0),\n",
    "        ot_loss=ot_loss\n",
    "    ))\n",
    "    loss.add(perceptual_bce(crossing_model, 3))\n",
    "    loss.add(perceptual_bce(crossing_model, 4))\n",
    "\n",
    "    grad_transformer = compose(strip_confidence_grads, coords_only_grads(n_steps - 150))\n",
    "\n",
    "    aligner = StatefulBatchAligner(device=device)\n",
    "    init_ot_aligner(aligner, loss_fn=loss, device=device,\n",
    "                    optimize_fn=make_default_optimize_fn(\n",
    "                        aligner, \n",
    "                        lr=0.25, \n",
    "                        transform_grads=grad_transformer,\n",
    "                        base_optimizer=optim.Adam,\n",
    "                    ))\n",
    "\n",
    "    aligner.add_callback(store_render_difference)\n",
    "    \n",
    "    return aligner\n",
    "    \n",
    "\n",
    "n_steps = 500\n",
    "    \n",
    "    \n",
    "class Model:\n",
    "    def __init__(self, data, results, gpu_idx, total_gpus):\n",
    "        self.results = results\n",
    "        self.gpu_idx = gpu_idx\n",
    "        self.total_gpus = total_gpus\n",
    "        self.data = data\n",
    "        \n",
    "        crossing_model = CrossingRefinerFull().to(f'cuda:{gpu_idx}')\n",
    "        crossing_model.load_state_dict(torch.load('../vecopt/weights/best_crossings_mult.pt'))\n",
    "        _ = crossing_model.train(False)\n",
    "        aligner = make_aligner(f'cuda:{gpu_idx}', n_steps)\n",
    "        self.worker = (IntermediateOutputAligner(aligner, n_steps=n_steps, crossing_model=crossing_model))\n",
    "    \n",
    "    def __call__(self):\n",
    "        for idx in range(self.gpu_idx, len(self.data), self.total_gpus):\n",
    "            sample = self.data[idx]\n",
    "            self.results.append(self.worker(sample.sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "models = [\n",
    "    Model(data, results, 0, 4),\n",
    "    Model(data, results, 1, 4),\n",
    "    Model(data, results, 2, 4),\n",
    "    Model(data, results, 3, 4)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=4, verbose=10)(delayed(model)() for model in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
